{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Cookbook - GPT4o-mini with RAG\n",
    "\n",
    "Instructions before running this notebook:\n",
    "1. pip install -r requirements.txt before running this notebook\n",
    "2. Create a .env file with your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import tiktoken\n",
    "import concurrent\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from IPython.display import Image, display, HTML\n",
    "from typing import List\n",
    "\n",
    "# To load OpenAI API Key from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "EMBEDDING_COST_PER_1K_TOKENS = 0.00013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Utility functions \n",
    "To create embeddings via batch + parallelized execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Batch Embedding Logic\n",
    "## Parallelize the execution of these embeddings to ensure that the script scales up for larger datasets. \n",
    "## Batchcify() splits input corpus into smaller chunks, embed_corpus() processes these chunks in parallel,\n",
    "## and get_embeddings() makes API calls to OpenAI embedding model.\n",
    "\n",
    "# Function to take in a list of text objects and return them as a list of embeddings\n",
    "# @retry is a decorator from the tenacity library that adds retry logic to the function. \n",
    "# If the function fails (e.g., due to API rate limits or network issues), it will:\n",
    "#       - Wait for a random exponential time between 1 and 40 seconds before retrying\n",
    "#       - Stop after 10 failed attempts\n",
    "#       - This makes  API calls more robust against temporary failures\n",
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(10))\n",
    "def get_embeddings(input: List):\n",
    "    response = client.embeddings.create(\n",
    "        input=input,\n",
    "        model=EMBEDDING_MODEL\n",
    "    ).data\n",
    "    return [data.embedding for data in response]\n",
    "\n",
    "# Splits an iterable into batches of size n. \n",
    "# Used in embed_corpus() to split text corpus into manageable chunks\n",
    "def batchify(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx : min(ndx + n, l)]\n",
    "     \n",
    "\n",
    "# Function for batching and parallel processing the embeddings\n",
    "def embed_corpus( \n",
    "    corpus: List[str], \n",
    "    batch_size=64, \n",
    "    num_workers=8, \n",
    "    max_context_len=8191,\n",
    "    ):\n",
    "    # Encode the corpus, truncating to max_context_len\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    encoded_corpus = [\n",
    "        encoded_article[:max_context_len] for encoded_article in encoding.encode_batch(corpus)\n",
    "    ]\n",
    "\n",
    "    # Calculate corpus statistics: the number of inputs, the total number of tokens, and the estimated cost to embed\n",
    "    num_tokens = sum(len(article) for article in encoded_corpus)\n",
    "    cost_to_embed_tokens = num_tokens / 1000 * EMBEDDING_COST_PER_1K_TOKENS\n",
    "    print(\n",
    "        f\"num_articles={len(encoded_corpus)}, num_tokens={num_tokens}, est_embedding_cost={cost_to_embed_tokens:.2f} USD\"\n",
    "    )\n",
    "\n",
    "    # Embed the corpus\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        \n",
    "        futures = [\n",
    "            executor.submit(get_embeddings, text_batch)\n",
    "            for text_batch in batchify(encoded_corpus, batch_size)\n",
    "        ]\n",
    "\n",
    "        with tqdm(total=len(encoded_corpus)) as pbar:\n",
    "            for _ in concurrent.futures.as_completed(futures):\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "        embeddings = []\n",
    "        for future in futures:\n",
    "            data = future.result()\n",
    "            embeddings.extend(data)\n",
    "\n",
    "        return embeddings\n",
    "    \n",
    "\n",
    "# Function to generate embeddings for a given column in a DataFrame\n",
    "def generate_embeddings(df, column_name):\n",
    "    # Initialize an empty list to store embeddings\n",
    "    descriptions = df[column_name].astype(str).tolist()\n",
    "    embeddings = embed_corpus(descriptions)\n",
    "\n",
    "    # Add the embeddings as a new column to the DataFrame\n",
    "    df['embeddings'] = embeddings\n",
    "    print(\"Embeddings created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the unstructured data (csv) into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id gender masterCategory subCategory articleType baseColour  season  \\\n",
      "0  27152    Men        Apparel     Topwear      Shirts       Blue  Summer   \n",
      "1  10469    Men        Apparel     Topwear     Tshirts     Yellow    Fall   \n",
      "2  17169    Men        Apparel     Topwear      Shirts     Maroon    Fall   \n",
      "3  56702    Men        Apparel     Topwear      Kurtas       Blue  Summer   \n",
      "4  47062  Women        Apparel  Bottomwear     Patiala      Multi    Fall   \n",
      "\n",
      "     year   usage                       productDisplayName  \n",
      "0  2012.0  Formal       Mark Taylor Men Striped Blue Shirt  \n",
      "1  2011.0  Casual   Flying Machine Men Yellow Polo Tshirts  \n",
      "2  2011.0  Casual  U.S. Polo Assn. Men Checks Maroon Shirt  \n",
      "3  2012.0  Ethnic                  Fabindia Men Blue Kurta  \n",
      "4  2012.0  Ethnic        Shree Women Multi Colored Patiala  \n",
      "Opened dataset successfully. Dataset has 1000 items of clothing.\n"
     ]
    }
   ],
   "source": [
    "styles_filepath = \"data/sample_clothes/sample_styles.csv\"\n",
    "styles_df = pd.read_csv(styles_filepath, on_bad_lines='skip')\n",
    "print(styles_df.head())\n",
    "print(\"Opened dataset successfully. Dataset has {} items of clothing.\".format(len(styles_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings from Dataframe (containing unstructured text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_articles=1000, num_tokens=8280, est_embedding_cost=0.00 USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1024it [00:05, 175.20it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created successfully.\n",
      "Writing embeddings to file ...\n",
      "Embeddings successfully stored in sample_styles_with_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# Creates embeddings for each product description (productDisplayName) \n",
    "# using the OpenAI Embeddings API via the parallelized technique above\n",
    "generate_embeddings(styles_df, 'productDisplayName')\n",
    "print(\"Writing embeddings to file ...\")\n",
    "styles_df.to_csv('data/sample_clothes/sample_styles_with_embeddings.csv', index=False)\n",
    "print(\"Embeddings successfully stored in sample_styles_with_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id gender masterCategory subCategory articleType baseColour  season  \\\n",
      "0  27152    Men        Apparel     Topwear      Shirts       Blue  Summer   \n",
      "1  10469    Men        Apparel     Topwear     Tshirts     Yellow    Fall   \n",
      "2  17169    Men        Apparel     Topwear      Shirts     Maroon    Fall   \n",
      "3  56702    Men        Apparel     Topwear      Kurtas       Blue  Summer   \n",
      "4  47062  Women        Apparel  Bottomwear     Patiala      Multi    Fall   \n",
      "\n",
      "     year   usage                       productDisplayName  \\\n",
      "0  2012.0  Formal       Mark Taylor Men Striped Blue Shirt   \n",
      "1  2011.0  Casual   Flying Machine Men Yellow Polo Tshirts   \n",
      "2  2011.0  Casual  U.S. Polo Assn. Men Checks Maroon Shirt   \n",
      "3  2012.0  Ethnic                  Fabindia Men Blue Kurta   \n",
      "4  2012.0  Ethnic        Shree Women Multi Colored Patiala   \n",
      "\n",
      "                                          embeddings  \n",
      "0  [0.006894612684845924, 0.00028893034323118627,...  \n",
      "1  [-0.04374878853559494, -0.008918779902160168, ...  \n",
      "2  [-0.028013937175273895, 0.058833517134189606, ...  \n",
      "3  [-0.0037015778943896294, 0.02956002578139305, ...  \n",
      "4  [-0.05243204906582832, 0.015965517610311508, -...  \n",
      "Opened dataset successfully. Dataset has 1000 items of clothing along with their embeddings.\n"
     ]
    }
   ],
   "source": [
    "## Read the embeddings from the CSV file, load into a DF\n",
    "# styles_df = pd.read_csv('data/sample_clothes/sample_styles_with_embeddings.csv', on_bad_lines='skip')\n",
    "\n",
    "## Convert the 'embeddings' column from string representations of lists to actual lists of floats\n",
    "# styles_df['embeddings'] = styles_df['embeddings'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "print(styles_df.head())\n",
    "print(\"Opened dataset successfully. Dataset has {} items of clothing along with their embeddings.\".format(len(styles_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Matching Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for cosine similarity\n",
    "def cosine_similarity_manual(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    vec1 = np.array(vec1, dtype=float)\n",
    "    vec2 = np.array(vec2, dtype=float)\n",
    "\n",
    "\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Custom retrieval function using cosine similarity\n",
    "def find_similar_items(input_embedding, embeddings, threshold=0.5, top_k=2):\n",
    "    \"\"\"\n",
    "    Find the most similar items based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "    input_embedding (list): The query embedding.\n",
    "    embeddings (list): The knowledge store embeddings to search through for the best matches.\n",
    "    threshold (float): \n",
    "        Minimum similarity score for a match to be considered valid. \n",
    "        A higher threshold results in closer (better) matches, \n",
    "        while a lower threshold allows for more items to be returned but less relevant.\n",
    "    top_k (int): The number of top similar items to return.\n",
    "\n",
    "    Returns:\n",
    "    list: A sorted top-k most similar items.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate cosine similarity between the input embedding and all other embeddings\n",
    "    similarities = [(index, cosine_similarity_manual(input_embedding, vec)) for index, vec in enumerate(embeddings)]\n",
    "    \n",
    "    # Filter out any similarities below the threshold\n",
    "    filtered_similarities = [(index, sim) for index, sim in similarities if sim >= threshold]\n",
    "    \n",
    "    # Sort the filtered similarities by similarity score\n",
    "    sorted_indices = sorted(filtered_similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Return the top-k most similar items\n",
    "    return sorted_indices\n",
    "\n",
    "# Function to find matching items using RAG\n",
    "def find_matching_items_with_rag(df_items, item_descs):\n",
    "   \"\"\"Take the input item descriptions and find the most similar items based on cosine similarity for each description.\"\"\"\n",
    "   \n",
    "   # Select the embeddings from the DataFrame.\n",
    "   embeddings = df_items['embeddings'].tolist()\n",
    "\n",
    "   similar_items = []\n",
    "   for desc in item_descs:\n",
    "      # Generate the embedding for the input item\n",
    "      input_embedding = get_embeddings([desc])    \n",
    "      # Find the most similar items based on cosine similarity\n",
    "      similar_indices = find_similar_items(input_embedding, embeddings, threshold=0.6)\n",
    "      similar_items += [df_items.iloc[i] for i in similar_indices]\n",
    "    \n",
    "   return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
